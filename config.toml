pretrained_model_name_or_path = "models/animagine-xl-3.1.safetensors"
train_data_dir = "train_data"
output_dir = "models/LoRA"
max_train_steps = 400
network_module = "networks.lora"
xformers = true
gradient_checkpointing = true
persistent_data_loader_workers = false
max_data_loader_n_workers = 0
enable_bucket = true
save_model_as = "safetensors"
lr_scheduler_num_cycles = 4
learning_rate = 5e-5
resolution = "1024,1024"
train_batch_size = 2
network_dim = 16
network_alpha = 16
optimizer_type = "came_pytorch.CAME"
optimizer_args = "weight_decay=1e-2" "betas=(0.9, 0.999, 0.9999)" "eps=(1e-30, 1e-16)"
mixed_precision = "fp16"
save_precision = "fp16"
lr_scheduler = "constant"
bucket_no_upscale = true
min_bucket_reso = 64
max_bucket_reso = 1024
caption_extension = ".txt"
seed = 42
network_train_unet_only = true
no_half_vae = true
cache_latents = true
cache_latents_to_disk = true
cache_text_encoder_outputs = true
cache_text_encoder_outputs_to_disk = true
fp8_base = true
console_log_simple = true
lowram = true
